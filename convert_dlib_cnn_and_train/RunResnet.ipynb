{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulate dlib network with a pretrained smaller Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch dep loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dep loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function,division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "import matplotlib as plt\n",
    "from graphviz import Digraph\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "print('dep loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lfw2']\n",
      "Loading imgs from:/mnt/mydata/dataset_faces/lfwa/lfw2/\n",
      "done loading 13233 imgs\n",
      "Face descriptors for:13145 images\n",
      "Writing files\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import io,data\n",
    "import glob\n",
    "import cv2\n",
    "import dlib\n",
    "import csv\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "\n",
    "def getImageList(completePath):\n",
    "    image_list = []\n",
    "    print('Loading imgs from:' + completePath)\n",
    "    for root,dirs,files in os.walk(completePath):\n",
    "        #for filename in glob.glob(completePath + '/*.jpg'): #assuming gif\n",
    "        for filename in files:\n",
    "            if filename.endswith((\".jpg\",\".jpeg\",\".png\",\".JPG\")):\n",
    "                fullName = str(root) + '/' + str(filename)\n",
    "                #print(fullName)\n",
    "                image_list.append(fullName)\n",
    "    print('done loading ' + str(len(image_list)) + \" imgs\")\n",
    "    return image_list\n",
    "\n",
    "def genOneList(dlibHogdetector,facerec,predictor,imagefullpath,savepath,NDIM,name):\n",
    "\n",
    "    image_list = getImageList(imagefullpath)\n",
    "    #print(image_list)\n",
    "    #descrp_Vector = np.zeros((len(image_list),NDIM))\n",
    "    descrp_Vector_dlib = []\n",
    "\n",
    "    ok_image_lst = []\n",
    "    ii = 0\n",
    "    for fn in image_list:\n",
    "        im = cv2.imread(fn)\n",
    "        #print(fn,im.shape)\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            if im.shape[2] > 3:\n",
    "                im = im[:,:,0:3]\n",
    "                print(\"reshaped\",im.shape)\n",
    "            imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            imgray = im\n",
    "            #create colour image\n",
    "            im = np.zeros((im.shape[0],im.shape[1],3))\n",
    "            im[:,:,0] = imgray\n",
    "            im[:,:,1] = imgray\n",
    "            im[:,:,2] = imgray\n",
    "        \n",
    "        # usa face detector\n",
    "        faces, FaceScores, Faceidx = dlibHogdetector.run(imgray,1,0.0) #frame, piramidal level, face threshold\n",
    "\n",
    "        faceArea = []\n",
    "        xar = []\n",
    "        yar = []\n",
    "        war = []\n",
    "        har = []\n",
    "        facesobj = dlib.full_object_detections() # array of full_object_detection objects\n",
    "        for k, d in enumerate(faces):\n",
    "            x = d.left()\n",
    "            y = d.top()\n",
    "            w = d.right() - x \n",
    "            h = d.bottom() - y\n",
    "            faceArea.append(w*h)\n",
    "            xar.append(x)\n",
    "            yar.append(y)\n",
    "            war.append(w)\n",
    "            har.append(h)\n",
    "\n",
    "        if len(faceArea) > 0: #dlib has detected at least a face\n",
    "            #faceArea = np.asarray(faceArea)\n",
    "            bestFaceIdx = np.argmax(faceArea)\n",
    "            dlibFaceRect = dlib.rectangle(int(xar[bestFaceIdx]),\n",
    "                                                int(yar[bestFaceIdx]),\n",
    "                                                int(xar[bestFaceIdx] + war[bestFaceIdx]),\n",
    "                                                int(yar[bestFaceIdx] + har[bestFaceIdx]))\n",
    "            shape = predictor(imgray, dlibFaceRect) #landmark detector on dlibFaceRect\n",
    "            facesobj.append(shape) #landmark detector\n",
    "            images = dlib.get_face_chips(im, facesobj, size=80, padding=0.0)          \n",
    "            cv2.imwrite(str(savepath) + 'imgs/img_' + name + '_'+ str(ii) + \"_\" + '.png',images[0])\n",
    "            descrp_Vector_dlib.append(facerec.compute_face_descriptor(im, shape, 1))\n",
    "            ii += 1\n",
    "            ok_image_lst.append(fn)\n",
    "\n",
    "\n",
    "    #assert(len(ok_image_lst) == len(descrp_Vector_openface) == len(descrp_Vector_dlib))\n",
    "    print(\"Face descriptors for:\" + str(len(ok_image_lst)) + ' images')\n",
    "    ok_image_lst = np.asarray(ok_image_lst)\n",
    "    descrp_Vector_dlib = np.asarray(descrp_Vector_dlib)\n",
    "    assert(descrp_Vector_dlib.shape[0] == len(ok_image_lst))\n",
    "    assert(descrp_Vector_dlib.shape[1] == NDIM)\n",
    "\n",
    "    print('Writing files')\n",
    "    #text_file = open(str(savepath) + name + \"_fnames.txt\", \"w\")\n",
    "    np.save(str(savepath)+name+\"_feat.npy\", descrp_Vector_dlib)\n",
    "    np.save(str(savepath)+name+\"_fname.npy\", ok_image_lst)\n",
    "    #for line in ok_image_lst:\n",
    "    #    text_file.write(line + \"\\n\")\n",
    "    #text_file.close()\n",
    "\n",
    "#### START ###\n",
    "NDIM = 128\n",
    "OUTIMGSIZE = 80\n",
    "\n",
    "completePath = \"/mnt/mydata/dataset_faces/lfwa/\"\n",
    "savepath = \"/mnt/mydata/dataset_faces/precomputed_feats/\"\n",
    "dlibshapePred_path = '../../SmartVend/FaceDet/objDetectors/landmarkDet/shape_predictor_68_face_landmarks.dat'\n",
    "dlibFaceRecpath = '../../SmartVend/FaceDet/faceRecmodels/dlib_face_recognition_resnet_model_v1.dat'\n",
    "\n",
    "dlibHogdetector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(dlibshapePred_path)\n",
    "facerec = dlib.face_recognition_model_v1(dlibFaceRecpath)\n",
    "\n",
    "\n",
    "dirlist = []\n",
    "for a,b,c in os.walk(completePath):\n",
    "    dirlist = b\n",
    "    break\n",
    "print(dirlist)\n",
    "for name in dirlist:\n",
    "    genOneList(dlibHogdetector,facerec,predictor,completePath+name+'/',savepath,NDIM,name)\n",
    "\n",
    "print('saved all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained resnet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained resnet, modify it for any input size and 128 dim output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# laod an imagenet pretrained network\n",
    "net = resnet18(pretrained=True,num_classes=1000)\n",
    "#print(net)\n",
    "\n",
    "#modify the net\n",
    "net.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "net.fc = nn.Linear(512,128)\n",
    "\n",
    "x = torch.rand(1,3,80,80)\n",
    "y = net(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### old  testcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from graphviz import Digraph\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "from graphviz import Digraph\n",
    "# make_dot was moved to https://github.com/szagoruyko/pytorchviz\n",
    "from torchviz import make_dot\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn(1,3,224,224)\n",
    "resnet18 = models.resnet18()\n",
    "print(resnet18.type)\n",
    "modules = list(resnet18.children())[:-1]\n",
    "resnet18 = nn.Sequential(*modules)\n",
    "print(resnet18.type)\n",
    "resnet18.fc = nn.Linear(512 * block.expansion, 128)\n",
    "print(resnet18.type)\n",
    "#print(resnet18)\n",
    "y = resnet18(Variable(x))\n",
    "print(y.shape)\n",
    "\n",
    "g = make_dot(y, params=dict(list(resnet18.named_parameters()) + [('x', x)]))\n",
    "print('end')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
